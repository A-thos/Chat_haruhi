{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-thos/Chat_haruhi/blob/main/notebook/ChatHaruhi2_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat凉宫春日 Chat-Haruhi-Suzumiya\n",
        "## Reviving Anime Character in Reality via Large Language Model\n",
        "\n",
        "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
        "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
        "[![Huggingface Gradio](https://img.shields.io/static/v1?label=Demo&message=Huggingface%20Gradio&color=orange)](https://huggingface.co/spaces/silk-road/ChatHaruhi)\n",
        "\n",
        "**Chat凉宫春日**是模仿凉宫春日等一系列动漫人物，使用近似语气、个性和剧情聊天的语言模型，\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary> 本项目由李鲁鲁, 冷子昂, 闫晨曦, 封小洋, scixing, 沈骏一, Aria Fei, 王皓, 米唯实, 冷月, JunityZhan, 贾曜恺, 吴平宇, 孙浩甄等开发。 </summary>\n",
        "\n",
        "本项目是一个开源项目，项目成员均在DataWhale等开源社区招募。\n",
        "\n",
        "李鲁鲁( [Cheng Li@SenseTime](https://github.com/LC1332) )发起了整个项目,并设计和实现了项目的大多数功能。\n",
        "\n",
        "冷子昂( [Ziang Leng@SenseTime](https://blairleng.github.io) )设计和实现了整体的ChatHaruhi1.0的训练,数据生成和后端架构。\n",
        "\n",
        "闫晨曦( [Chenxi Yan@Chengdu University of Information Technology](https://github.com/todochenxi) )实现和维护了ChatHaruhi1.0版本的后端。\n",
        "\n",
        "沈骏一( [Junyi Shen@Zhejiang University](https://github.com/J1shen) )实现了训练代码,参与了训练数据集生成。\n",
        "\n",
        "王皓( [Hao Wang](https://github.com/wanghao07456) )收集了武林外传的台本数据,参与了增广数据的生成。\n",
        "\n",
        "米唯实( [Weishi MI@Tsinghua University](https://github.com/hhhwmws0117) )参与了增广数据生成，进行了chatharuhi2.0的实现（with 李鲁鲁），并将其上传到了公用Pypi账号。\n",
        "\n",
        "Yaying Fei( [Aria Fei@Beijing University of Technology](https://ariafyy.github.io/) )实现了台本工具 ASR 功能,参与了Openness-Aware Personality paper分支项目。\n",
        "\n",
        "封小洋( [Xiaoyang Feng@Nanjing Agricultural University](https://github.com/fengyunzaidushi) )整合了台本识别工具功能,参与了Openness-Aware Personality paper分支项目。\n",
        "\n",
        "冷月( [Song Yan](https://github.com/zealot52099) )收集了big bang thoery的数据。实现了台本格式转换功能。\n",
        "\n",
        "scixing(汪好盛)( [HaoSheng Wang](https://github.com/ssccinng) )实现了台本工具中声纹识别功能,以及tts-vits语音合成功能。\n",
        "\n",
        "Linkang Zhan( [JunityZhan@Case Western Reserve University](https://github.com/JunityZhan) ) 收集了原神的system prompt和故事数据。\n",
        "\n",
        "贾曜恺( [Yaokai Jia](https://github.com/KaiJiaBrother) )实现了Vue版本的前端,并且在心理项目中实践了Bert的GPU抽取。\n",
        "\n",
        "吴平宇( [Pingyu Wu@Juncai Shuyun](https://github.com/wpydcr) )帮助部署了第一版本的训练代码。\n",
        "\n",
        "孙浩甄( [Haozhen Sun@Tianjin University] )绘制了ChatHaruhi角色的拼图。\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "这个脚本展示了ChatHaruhi 2.0的基本使用方式\n",
        "\n",
        "本脚本使用LangChain based的openAI的turbo3.5接口作为语言模型\n",
        "\n",
        "This notebook demonstrates the basic usage of ChatHaruhi 2.0.\n",
        "\n",
        "This script using the LangChain based openAI turbo 3.5 API as the language model."
      ],
      "metadata": {
        "id": "BXlJzdARn9pm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 首先使用pip install导入"
      ],
      "metadata": {
        "id": "8Pm8IzBs_epf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and configure environment"
      ],
      "metadata": {
        "id": "XBkR6a9uANQI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ktql7lSXruLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "outputId": "2accc470-7b97-424f-a6ea-7054a0336af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpLIsov4ruil"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec==2024.9.0 in /usr/local/lib/python3.10/dist-packages (2024.9.0)\n"
          ]
        }
      ],
      "source": [
        "pip install fsspec==2024.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have removed chromadb recently"
      ],
      "metadata": {
        "id": "5xNRn75cEn1d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PnD9adsyh5j4"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai tiktoken langchain datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf /content/Haruhi-2-Dev\n",
        "!git clone https://github.com/LC1332/Haruhi-2-Dev\n",
        "%cd /content/Haruhi-2-Dev"
      ],
      "metadata": {
        "id": "FbL3gGsqDV6s",
        "outputId": "de7ab060-cb26-47e0-f6fa-f00213916418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Haruhi-2-Dev'...\n",
            "remote: Enumerating objects: 1055, done.\u001b[K\n",
            "remote: Counting objects: 100% (362/362), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 1055 (delta 248), reused 313 (delta 212), pack-reused 693 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1055/1055), 106.36 MiB | 39.84 MiB/s, done.\n",
            "Resolving deltas: 100% (578/578), done.\n",
            "/content/Haruhi-2-Dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may also using pip install chatharuhi to intall the library\n",
        "\n",
        "but change\n",
        "\n",
        "```python\n",
        "import ChatHaruhi from ChatHaruhi\n",
        "```\n",
        "\n",
        "into\n",
        "\n",
        "```python\n",
        "import ChatHaruhi from chatharuhi\n",
        "```\n"
      ],
      "metadata": {
        "id": "xTWVmsv8Ea79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "base = \"https://apis.wumingai.com/v1\" # add you key here\n",
        "base_bytes = base.encode()\n",
        "os.environ[\"OPENAI_API_BASE\"] = base_bytes.decode('utf-8')\n",
        "key = \"sk-kyCLNJCOHRzw1kko7aE31cD128964f18925039Bf200679D2\" # add you key here\n",
        "key_bytes = key.encode()\n",
        "os.environ[\"OPENAI_API_KEY\"] = key_bytes.decode('utf-8')"
      ],
      "metadata": {
        "id": "hhvvhg11ifIv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now role_from_hf is the most suggested way to load the Character"
      ],
      "metadata": {
        "id": "ddZkm2x0FGK9"
      }
    },
    {
      "source": [
        "!pip install langchain_community"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "43Qfy_RktFF8",
        "outputId": "ef09b76f-c9ef-46b3-cb05-b7e35724ea70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.15)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.6->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi import ChatHaruhi\n",
        "\n",
        "chatbot = ChatHaruhi( role_from_hf = \"silk-road/ChatHaruhi-RolePlaying/haruhi\",\\\n",
        "                      llm = 'openai' ,\\\n",
        "                      verbose = True)"
      ],
      "metadata": {
        "id": "eFc--7XoDhC7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chatbot.chat(role='阿虚', text = 'Haruhi, 你好啊')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "AZJhNH68DqNM",
        "outputId": "c0fe7dc4-817a-4705-9a71-15aecabf6e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "春日:「哼，阿虚！你今天怎么这么迟？难道是想让我等你吗？可别忘了，SOS团的活动可不能耽误！」\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the role was saved at\n",
        "\n",
        "https://huggingface.co/datasets/silk-road/ChatHaruhi-RolePlaying\n",
        "\n",
        "this hugging face repo saved 32 characters, you may find other chacaters in\n",
        "\n",
        "https://github.com/LC1332/Chat-Haruhi-Suzumiya/tree/main/characters/novel_collecting\n",
        "\n",
        "if you download a local jsonl file you may use the interface like\n",
        "\n",
        "\n",
        "```python\n",
        "chatbot = ChatHaruhi( role_from_jsonl = \"Your Local File\",\\\n",
        "                      llm = 'openai' ,\\\n",
        "                      verbose = True)\n",
        "```\n"
      ],
      "metadata": {
        "id": "Ul79S0D-E5qq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the character has not been build in ChatHaruhi-jsonl format\n",
        "\n",
        "you need to prepare\n",
        "\n",
        "- all story files into a folder\n",
        "- the system prompt\n",
        "\n",
        "and use this interface\n",
        "\n",
        "```python\n",
        "from chatharuhi import ChatHaruhi\n",
        "\n",
        "text_folder = '/content/Haruhi-2-Dev/data/characters/haruhi/texts'\n",
        "\n",
        "system_prompt = '/content/Haruhi-2-Dev/data/characters/haruhi/system_prompt.txt'\n",
        "\n",
        "chatbot = ChatHaruhi( system_prompt = system_prompt,\\\n",
        "                      llm = 'debug' ,\\\n",
        "                      story_text_folder = text_folder)\n",
        "\n",
        "chatbot.chat(role='阿虚', text = 'Haruhi, 你好啊')\n",
        "```\n",
        "\n",
        "see example here https://github.com/LC1332/Haruhi-2-Dev/blob/main/notebook/test_PrintLLM.ipynb"
      ],
      "metadata": {
        "id": "MRyt70ODFoJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with Local Model\n",
        "\n",
        "see this notebook\n",
        "\n",
        "https://github.com/LC1332/Chat-Haruhi-Suzumiya/blob/main/notebook/ChatHaruhi_x_Qwen7B.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "vR2pYvcfGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Support\n",
        "\n",
        "Currently we support\n",
        "\n",
        "\"luotuo_openai\" for Chinese using a distilled LuotuoBert model / English using openai api (text-embedding-ada-002)\n",
        "\n",
        "\"bge_en\" using bge_small_en_v1.5\n",
        "\n",
        "\"bge_zh\" using bge_small_zh_v1.5\n",
        "\n",
        "Now, we need corresponding embeddings in the jsonl library.\n",
        "\n",
        "However, we are currently developing an adapter that aims to achieve any-to-any conversion.\n"
      ],
      "metadata": {
        "id": "xDMJDZn2HQBz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bA-_RLUlHPW8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}